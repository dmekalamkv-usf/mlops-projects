{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking multiple SVM model performance using MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Following the generation of our synthetic dataset for E-commerce Shipping Time Prediction, this notebook is dedicated to applying and analyzing Support Vector Machine (SVM) models to our dataset. Our focus will be on predicting the delivery time of packages, a regression problem, utilizing the SVM regression variant, Support Vector Regression (SVR).\n",
    "\n",
    "\n",
    "- **Objective:** Apply SVM models to predict delivery times for an e-commerce shipping dataset and use MLflow to track the performace of each model.\n",
    "- **Dataset Features:** Distance to destination and package weight.\n",
    "- **Target Variable:** Delivery time in hours.\n",
    "- **Analysis Focus:**\n",
    "    - Examining the effect of different SVM kernels (linear, RBF, poly) on prediction accuracy.\n",
    "    - Utilizing hyper-parameter tuning to enhance model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I donot need the random seed anymore as using mlflow I can regenerate the model formed or the results obtained at any time or any run of the code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as it is synthetically generated there in need to furture clean and process the data. So we can import and move on with our application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>weight</th>\n",
       "      <th>delivery_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>911.9</td>\n",
       "      <td>101</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>419.0</td>\n",
       "      <td>163</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>614.5</td>\n",
       "      <td>91</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance  weight  delivery_time\n",
       "0     911.9     101            112\n",
       "1     419.0     163            110\n",
       "2     614.5      91            110"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/delivery_time.csv') # let's use the same data as we did in the logistic regression example\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split:\n",
    "I am choosing a train test split of 20% for the following reasons\n",
    "- Balanced Dataset Size: Using a test size of 0.2 provides a good balance between training and testing datasets, ensuring enough data for model training while still having a substantial amount to validate model performance.\n",
    "- Sufficient Testing Data: With 1000 observations, a 0.2 split ensures 200 observations for testing, which is adequate to assess model accuracy and generalizability without significantly reducing the training set size.\n",
    "- Avoid Overfitting: A larger training set (80%) helps in building a more accurate model while the testing set (20%) is sufficient to evaluate overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn to split df into a training set and a test set\n",
    "\n",
    "X = df[['distance','weight']]\n",
    "y = df['delivery_time']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/09 11:29:19 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logged at level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "mlflow.set_experiment(\"svm_linear\")\n",
    "mlflow.start_run()\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing Performance metrics for the data\n",
    "\n",
    "To evaluate and compare the performance of our tuned SVM models, we can  will consider several metrics: \n",
    "- Mean Absolute Error (MAE), \n",
    "- Mean Squared Error (MSE), and the \n",
    "- R-squared score.\n",
    "\n",
    "but I will be optimizing on MSE as it optimizes on the overall accuracy on delivery times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"MSE\": [], \"MAE\": [], \"R2\": [], \"Parameters\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling and Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  SVM Regression model using linear kernal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/09 11:29:26 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"C:\\Users\\Dheeraj Mekala\\anaconda3\\lib\\site-packages\\mlflow\\types\\utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/09 11:31:03 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"C:\\Users\\Dheeraj Mekala\\anaconda3\\lib\\site-packages\\mlflow\\types\\utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2024/03/09 11:31:13 INFO mlflow.sklearn.utils: Logging the 5 best runs, no runs will be omitted.\n"
     ]
    }
   ],
   "source": [
    "# defining parameter range \n",
    "param_grid = {'C': [ 0.5, 1, 5, 10],  \n",
    "              'kernel': ['linear']}\n",
    "  \n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid, scoring='neg_mean_squared_error', refit = True, verbose = 3, n_jobs=-1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "_ = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim is to use both gridCv and Mlflow and realtivly comapre my current approach with using MLflow. Now after I looged into the MLflow ui I viewed the cv_results.csv document generated that captured all 4 paramters used in the cv and scored them with a detailed analysis of the every iteration gridCv went through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     distance  weight\n",
      "993     418.8     143\n",
      "859     940.3     150\n",
      "298     484.0      70\n",
      "553    1047.3     127\n",
      "672     570.6     171\n",
      "..        ...     ...\n",
      "679     837.5      35\n",
      "722     409.8     137\n",
      "215     990.0      61\n",
      "653     778.8     121\n",
      "150     413.8      71\n",
      "\n",
      "[200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print (X_test)\n",
    "#X_test =X_test.drop(\"delivery_time\",axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/09 11:31:14 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"C:\\Users\\Dheeraj Mekala\\anaconda3\\lib\\site-packages\\mlflow\\types\\utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'kernel': 'linear'}\n",
      "SVR(C=1, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "print(grid.best_estimator_)\n",
    "\n",
    "\n",
    "y_pred = grid.predict(X_test) \n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "performance = pd.concat([performance, pd.DataFrame({\"model\": [\"SVM Linear\"], \"MSE\": [mse], \"MAE\": [mae], \"R2\": [r2], \"Parameters\": [grid.best_params_]})])\n",
    "\n",
    "mlflow.sklearn.log_model(grid.best_estimator_, \"best_model\")\n",
    "\n",
    "mlflow.end_run()\n",
    "\n",
    "run = mlflow.last_active_run()\n",
    "\n",
    "run_id = run.info.run_id\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78418611513b4e31879739d230a7238a\n"
     ]
    }
   ],
   "source": [
    "print(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['y'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DHEERA~1\\AppData\\Local\\Temp/ipykernel_26740/1685566897.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4904\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4905\u001b[0m         \"\"\"\n\u001b[1;32m-> 4906\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4907\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4908\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4148\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4149\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4150\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4152\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4184\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4185\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6015\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6017\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6019\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['y'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#X_test = X_test.drop('y',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dheeraj Mekala\\anaconda3\\lib\\site-packages\\mlflow\\types\\utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2024/03/09 11:33:54 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2024/03/09 11:33:54 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "2024/03/09 11:33:54 WARNING mlflow.models.evaluation.default_evaluator: Computing sklearn model score failed: ValueError(\"Passing extra keyword arguments to GridSearchCV.score is only supported if enable_metadata_routing=True, which you can set using `sklearn.set_config`. See the User Guide <https://scikit-learn.org/stable/metadata_routing.html> for more details. Extra parameters passed are: {'sample_weight'}\"). Set logging level to DEBUG to see the full traceback.\n",
      "C:\\Users\\Dheeraj Mekala\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "2024/03/09 11:33:54 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "2024/03/09 11:33:54 WARNING mlflow.models.evaluation.default_evaluator: SHAP or matplotlib package is not installed, so model explainability insights will not be logged.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.evaluation.base.EvaluationResult at 0x1e4f3c9cc40>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "eval_data = X_test.copy()\n",
    "\n",
    "eval_data['delivery_time']= y_test \n",
    "mlflow.evaluate(\n",
    "f\"runs:/{run_id}/model\",\n",
    "eval_data,\n",
    "targets=\"delivery_time\",\n",
    "model_type=\"regressor\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Linear</td>\n",
       "      <td>28.960946</td>\n",
       "      <td>4.523503</td>\n",
       "      <td>0.921741</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model        MSE       MAE        R2                    Parameters\n",
       "0  SVM Linear  28.960946  4.523503  0.921741  {'C': 1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   SVM regression model using rbf kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/09 11:33:54 INFO mlflow.tracking.fluent: Experiment with name 'svm_rbf' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"svm_rbf\")\n",
    "mlflow.start_run()\n",
    "mlflow.sklearn.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/09 11:33:55 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"C:\\Users\\Dheeraj Mekala\\anaconda3\\lib\\site-packages\\mlflow\\types\\utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/09 11:33:57 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"C:\\Users\\Dheeraj Mekala\\anaconda3\\lib\\site-packages\\mlflow\\types\\utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2024/03/09 11:34:04 INFO mlflow.sklearn.utils: Logging the 5 best runs, 15 runs will be omitted.\n"
     ]
    }
   ],
   "source": [
    "# defining parameter range \n",
    "param_grid = {'C': [0.1, 1, 10, 100],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['rbf']}\n",
    "  \n",
    "grid = GridSearchCV(SVR(), param_grid, scoring='neg_mean_squared_error', refit = True, verbose = 3, n_jobs=-1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "_ = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/09 11:34:04 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"C:\\Users\\Dheeraj Mekala\\anaconda3\\lib\\site-packages\\mlflow\\types\\utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "SVR(C=10, gamma=0.0001)\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "print(grid.best_estimator_)\n",
    "\n",
    "y_pred = grid.predict(X_test) \n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "performance = pd.concat([performance, pd.DataFrame({\"model\": [\"SVM rbf\"], \"MSE\": [mse], \"MAE\": [mae], \"R2\": [r2],\"Parameters\": [grid.best_params_]})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()\n",
    "\n",
    "run = mlflow.last_active_run()\n",
    "\n",
    "run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dheeraj Mekala\\anaconda3\\lib\\site-packages\\mlflow\\types\\utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2024/03/09 11:34:04 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2024/03/09 11:34:04 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "2024/03/09 11:34:04 WARNING mlflow.models.evaluation.default_evaluator: Computing sklearn model score failed: ValueError(\"Passing extra keyword arguments to GridSearchCV.score is only supported if enable_metadata_routing=True, which you can set using `sklearn.set_config`. See the User Guide <https://scikit-learn.org/stable/metadata_routing.html> for more details. Extra parameters passed are: {'sample_weight'}\"). Set logging level to DEBUG to see the full traceback.\n",
      "C:\\Users\\Dheeraj Mekala\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "2024/03/09 11:34:04 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "2024/03/09 11:34:04 WARNING mlflow.models.evaluation.default_evaluator: SHAP or matplotlib package is not installed, so model explainability insights will not be logged.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.evaluation.base.EvaluationResult at 0x1e4f0df3cd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.evaluate(\n",
    "f\"runs:/{run_id}/model\",\n",
    "eval_data,\n",
    "targets=\"delivery_time\",\n",
    "model_type=\"regressor\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM classification model using polynomial kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/09 11:34:05 INFO mlflow.tracking.fluent: Experiment with name 'svm_poly' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"svm_poly\")\n",
    "mlflow.start_run()\n",
    "mlflow.sklearn.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/09 11:34:05 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"C:\\Users\\Dheeraj Mekala\\anaconda3\\lib\\site-packages\\mlflow\\types\\utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/09 11:34:45 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"C:\\Users\\Dheeraj Mekala\\anaconda3\\lib\\site-packages\\mlflow\\types\\utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2024/03/09 11:34:50 INFO mlflow.sklearn.utils: Logging the 5 best runs, 59 runs will be omitted.\n"
     ]
    }
   ],
   "source": [
    "# defining parameter range \n",
    "param_grid = {'C': [0.01, 0.1, 0.5, 1, 5, 10, 50, 100],  \n",
    "              'coef0': [0.01, 0.1, 0.5, 1, 5, 10, 50, 100],\n",
    "              'kernel': ['poly']}\n",
    "  \n",
    "grid = GridSearchCV(SVR(), param_grid, scoring='neg_mean_squared_error', refit = True, verbose = 3, n_jobs=-1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "_ = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/09 11:34:50 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"C:\\Users\\Dheeraj Mekala\\anaconda3\\lib\\site-packages\\mlflow\\types\\utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 5, 'coef0': 5, 'kernel': 'poly'}\n",
      "SVR(C=5, coef0=5, kernel='poly')\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "print(grid.best_estimator_)\n",
    "\n",
    "y_pred = grid.predict(X_test) \n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "performance = pd.concat([performance, pd.DataFrame({\"model\": [\"SVM Poly\"], \"MSE\": [mse], \"MAE\": [mae], \"R2\": [r2], \"Parameters\": [grid.best_params_]})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()\n",
    "\n",
    "run = mlflow.last_active_run()\n",
    "\n",
    "run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dheeraj Mekala\\anaconda3\\lib\\site-packages\\mlflow\\types\\utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2024/03/09 11:34:51 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2024/03/09 11:34:51 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "2024/03/09 11:34:51 WARNING mlflow.models.evaluation.default_evaluator: Computing sklearn model score failed: ValueError(\"Passing extra keyword arguments to GridSearchCV.score is only supported if enable_metadata_routing=True, which you can set using `sklearn.set_config`. See the User Guide <https://scikit-learn.org/stable/metadata_routing.html> for more details. Extra parameters passed are: {'sample_weight'}\"). Set logging level to DEBUG to see the full traceback.\n",
      "C:\\Users\\Dheeraj Mekala\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "2024/03/09 11:34:51 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "2024/03/09 11:34:51 WARNING mlflow.models.evaluation.default_evaluator: SHAP or matplotlib package is not installed, so model explainability insights will not be logged.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.evaluation.base.EvaluationResult at 0x1e4f0e657c0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.evaluate(\n",
    "f\"runs:/{run_id}/model\",\n",
    "eval_data,\n",
    "targets=\"delivery_time\",\n",
    "model_type=\"regressor\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performances of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Linear</td>\n",
       "      <td>28.960946</td>\n",
       "      <td>4.523503</td>\n",
       "      <td>0.921741</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Poly</td>\n",
       "      <td>29.654246</td>\n",
       "      <td>4.563022</td>\n",
       "      <td>0.919867</td>\n",
       "      <td>{'C': 5, 'coef0': 5, 'kernel': 'poly'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM rbf</td>\n",
       "      <td>35.787535</td>\n",
       "      <td>5.045667</td>\n",
       "      <td>0.903294</td>\n",
       "      <td>{'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model        MSE       MAE        R2  \\\n",
       "0  SVM Linear  28.960946  4.523503  0.921741   \n",
       "0    SVM Poly  29.654246  4.563022  0.919867   \n",
       "0     SVM rbf  35.787535  5.045667  0.903294   \n",
       "\n",
       "                                    Parameters  \n",
       "0                 {'C': 1, 'kernel': 'linear'}  \n",
       "0       {'C': 5, 'coef0': 5, 'kernel': 'poly'}  \n",
       "0  {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.sort_values(by=\"MSE\", ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary and Conclusion\n",
    "\n",
    "- **Model Performance:** Linear and Polynomial kernels showed the best performance, optimized for Mean Squared Error (MSE) to enhance accuracy.\n",
    "\n",
    "### Pros and Cons of Each Model Choice:\n",
    "- **Linear Kernel:** Chosen for its simplicity and ease of interpretation. It works well for linearly separable data.\n",
    "- **Polynomial Kernel:** Selected for its ability to handle non-linear relationships, offering flexibility in modeling complex patterns.\n",
    "- **RBF Kernel:** Though it is a powerful kernel capable of complex modelings, it did not perform as expected in our case, likely due to overfitting or the specific characteristics of our data.\n",
    "\n",
    "### Pros and Cons of Each Metric Choice:\n",
    "- **MSE (Mean Squared Error):** Focuses on penalizing larger errors more heavily, making it suitable for our regression problem where accuracy in predicting delivery times is critical. However, it can be sensitive to outliers.\n",
    "- **MAE (Mean Absolute Error):** Provides a straightforward measure of error magnitude without heavily penalizing larger errors, offering a more robust metric against outliers compared to MSE. Its downside is that it might not reflect the performance on datasets with large errors well.\n",
    "- **R2 (R-Squared):** Indicates the proportion of variance in the dependent variable that is predictable from the independent variables. While it gives a good indication of fit quality, it doesn't specify the error magnitude.\n",
    "\n",
    "### Our Result:\n",
    "Upon comparing the linear and polynomial models, both have their advantages. The linear model's simplicity and interpretability make it highly valuable for straightforward problems or when explaining the model to stakeholders is necessary. The polynomial model's flexibility is advantageous for capturing more complex relationships in the data, although at the risk of overfitting.\n",
    "\n",
    "### Linear vs. Polynomial - Pros, Cons, and Output Comparison:\n",
    "- **Linear Kernel:** Its main advantage lies in simplicity and lower risk of overfitting, making it highly efficient for datasets where the relationship between the variables is approximately linear.\n",
    "- **Polynomial Kernel:** Offers the ability to capture complex relationships but requires careful tuning of parameters to avoid overfitting.\n",
    "\n",
    "### Why Choosing Linear is Better than Any Other Model in the Final Output:\n",
    "The linear model's simplicity, efficiency, and ease of interpretation often make it the preferred choice, especially in a business context where decisions need to be explained to non-technical stakeholders. It strikes a balance between accuracy and model complexity, ensuring that the model is both practical and reliable.\n",
    "\n",
    "### What These advantages mean in the context of an e-commerce platform:\n",
    "In the context of e-commerce shipping time prediction, choosing the right model impacts not only the accuracy of predictions but also the operational efficiency and customer satisfaction. A linear model, with its balance of simplicity and effectiveness, supports timely and reliable delivery predictions. This reliability is crucial for planning, resource allocation, and enhancing the overall customer experience by setting realistic expectations for delivery times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
